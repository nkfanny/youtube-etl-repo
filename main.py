from flask import Flask, jsonify
from googleapiclient.discovery import build
from google.oauth2.service_account import Credentials as ServiceAccountCredentials
from google.oauth2.credentials import Credentials as UserCredentials
import gspread
from datetime import datetime, timedelta
import os
import json
import re

app = Flask(__name__)

# Configuration
SPREADSHEET_NAME = "YouTube_Intelligence"
SPREADSHEET_ID = "1bvob7xaoO5X-RHAhl34ZVcX2IH2qYufVy9aKaUdNXxU"
CHANNEL_ID = "UCS1m_ZhEAbQKfvIdAwoax2A"

@app.route('/')
def hello():
    return jsonify({
        'status': 'success',
        'message': 'YouTube ETL Service - Hybride Phase 1 + 2!',
        'service': 'youtube-etl',
        'version': '5.0',
        'authentication': 'YouTube OAuth + Sheets Service Account',
        'endpoints': ['/etl', '/test', '/test-youtube', '/test-sheets']
    })

@app.route('/test')
def test_basic():
    """Test basique du service"""
    try:
        print("=== üß™ TEST BASIQUE DU SERVICE ===")
        print(f"üïê {datetime.now().isoformat()}")
        
        # Variables d'environnement
        env_status = {}
        for var in ['YOUTUBE_TOKEN_JSON', 'GOOGLE_SA_JSON', 'PORT', 'K_SERVICE']:
            value = os.environ.get(var)
            env_status[var] = 'D√âFINIE' if value else 'MANQUANTE'
            print(f"   üìã {var}: {env_status[var]}")
        
        result = {
            'status': 'success',
            'message': 'Service op√©rationnel',
            'timestamp': datetime.now().isoformat(),
            'environment': env_status,
            'channel_id': CHANNEL_ID,
            'spreadsheet_id': SPREADSHEET_ID,
            'auth_ready': {
                'youtube': env_status.get('YOUTUBE_TOKEN_JSON') == 'D√âFINIE',
                'sheets': env_status.get('GOOGLE_SA_JSON') == 'D√âFINIE'
            }
        }
        
        print("‚úÖ Test basique r√©ussi")
        return jsonify(result)
        
    except Exception as e:
        print(f"‚ùå Erreur test basique: {e}")
        return jsonify({
            'status': 'error',
            'message': str(e),
            'timestamp': datetime.now().isoformat()
        }), 500

@app.route('/test-youtube')
def test_youtube():
    """Test sp√©cifique YouTube Analytics"""
    try:
        print("=== üì∫ TEST YOUTUBE ANALYTICS ===")
        
        # R√©cup√©rer les credentials YouTube
        youtube_creds = get_youtube_credentials()
        if not youtube_creds:
            raise Exception("YouTube credentials non configur√©s")
        
        print("‚úÖ Credentials YouTube r√©cup√©r√©s")
        
        # Initialiser les services
        youtube_service, analytics_service = get_youtube_services(youtube_creds)
        print("‚úÖ Services YouTube initialis√©s")
        
        # Test Analytics simple
        end_date = datetime.now().date()
        start_date = end_date - timedelta(days=3)
        
        print(f"üîç Test Analytics p√©riode: {start_date} ‚Üí {end_date}")
        
        response = analytics_service.reports().query(
            ids='channel==MINE',
            startDate=str(start_date),
            endDate=str(end_date),
            metrics='views,estimatedMinutesWatched',
            dimensions='day',
            sort='day'
        ).execute()
        
        rows = response.get('rows', [])
        print(f"‚úÖ Analytics r√©ponse: {len(rows)} lignes")
        
        return jsonify({
            'status': 'success',
            'message': 'YouTube Analytics accessible',
            'data_rows': len(rows),
            'sample_data': rows[:2] if rows else [],
            'timestamp': datetime.now().isoformat()
        })
        
    except Exception as e:
        print(f"‚ùå Erreur YouTube: {e}")
        return jsonify({
            'status': 'error',
            'message': str(e),
            'type': type(e).__name__,
            'timestamp': datetime.now().isoformat()
        }), 500

@app.route('/test-sheets')
def test_sheets():
    """Test sp√©cifique Google Sheets"""
    try:
        print("=== üìä TEST GOOGLE SHEETS ===")
        
        # R√©cup√©rer le client Sheets
        sheets_client = get_sheets_client()
        if not sheets_client:
            raise Exception("Sheets credentials non configur√©s")
        
        print("‚úÖ Client Sheets r√©cup√©r√©")
        
        # Test d'acc√®s au spreadsheet
        spreadsheet = sheets_client.open_by_key(SPREADSHEET_ID)
        print(f"‚úÖ Spreadsheet ouvert: {spreadsheet.title}")
        
        # Lister les worksheets
        worksheets = spreadsheet.worksheets()
        worksheet_names = [ws.title for ws in worksheets]
        print(f"‚úÖ Worksheets trouv√©s: {worksheet_names}")
        
        return jsonify({
            'status': 'success',
            'message': 'Google Sheets accessible',
            'spreadsheet_title': spreadsheet.title,
            'worksheets': worksheet_names,
            'timestamp': datetime.now().isoformat()
        })
        
    except Exception as e:
        print(f"‚ùå Erreur Sheets: {e}")
        return jsonify({
            'status': 'error',
            'message': str(e),
            'type': type(e).__name__,
            'timestamp': datetime.now().isoformat()
        }), 500

@app.route('/etl')
def run_etl():
    """ETL YouTube complet - Phase 1 & 2 Hybride"""
    try:
        print("=== üöÄ D√âBUT ETL YOUTUBE HYBRIDE (PHASE 1 + 2) ===")
        start_time = datetime.now()
        print(f"üïê D√©but: {start_time.isoformat()}")
        
        # 1. Initialiser les credentials
        print("1Ô∏è‚É£ Initialisation des authentifications...")
        youtube_creds = get_youtube_credentials()
        sheets_client = get_sheets_client()
        
        if not youtube_creds:
            raise Exception("YouTube credentials manquants")
        if not sheets_client:
            raise Exception("Sheets credentials manquants")
        
        print("‚úÖ Double authentification pr√™te")
        
        # 2. Initialiser les services YouTube
        print("2Ô∏è‚É£ Initialisation services YouTube...")
        youtube_service, analytics_service = get_youtube_services(youtube_creds)
        print("‚úÖ Services YouTube pr√™ts")
        
        # 3. Calculer les dates
        end_date = datetime.now().date()
        start_date = end_date - timedelta(days=6)
        print(f"üìÖ P√©riode ETL: {start_date} ‚Üí {end_date}")
        
        # 4. PHASE 1 : Donn√©es quotidiennes par cha√Æne
        print("3Ô∏è‚É£ PHASE 1 : R√©cup√©ration Daily Channel Data...")
        daily_rows = get_daily_channel_data(analytics_service, str(start_date), str(end_date))
        print(f"‚úÖ Phase 1: {len(daily_rows)} lignes r√©cup√©r√©es")
        
        # 5. PHASE 2 : Donn√©es par vid√©o (7 jours)
        print("4Ô∏è‚É£ PHASE 2 : R√©cup√©ration Video Performance Data...")
        video_rows = get_video_performance_data(analytics_service, str(start_date), str(end_date))
        print(f"‚úÖ Phase 2: {len(video_rows)} lignes r√©cup√©r√©es")
        
        # 6. Sauvegarder Phase 1
        print("5Ô∏è‚É£ Sauvegarde Daily Channel Data...")
        if daily_rows:
            save_daily_channel_data(sheets_client, daily_rows)
            print("‚úÖ Phase 1 sauvegard√©e dans Raw_Daily_Data")
        
        # 7. Sauvegarder Phase 2
        print("6Ô∏è‚É£ Sauvegarde Video Performance Data...")
        if video_rows:
            save_video_performance_data(sheets_client, video_rows)
            print("‚úÖ Phase 2 sauvegard√©e dans Video_Performance_Data")
        
        # 8. R√©sultat final
        execution_time = (datetime.now() - start_time).total_seconds()
        print(f"‚úÖ ETL HYBRIDE TERMIN√â en {execution_time:.2f}s")
        
        return jsonify({
            'status': 'success',
            'message': 'ETL Hybride Phase 1+2 ex√©cut√© avec succ√®s',
            'execution_details': {
                'start_time': start_time.isoformat(),
                'end_time': datetime.now().isoformat(),
                'duration_seconds': round(execution_time, 2),
                'period': {
                    'start': str(start_date),
                    'end': str(end_date)
                },
                'phase1_daily_rows': len(daily_rows),
                'phase2_video_rows': len(video_rows),
                'channel_id': CHANNEL_ID,
                'spreadsheet_id': SPREADSHEET_ID
            },
            'timestamp': datetime.now().isoformat()
        })
        
    except Exception as e:
        print(f"‚ùå ERREUR ETL: {e}")
        return jsonify({
            'status': 'error',
            'error_details': {
                'type': type(e).__name__,
                'message': str(e),
                'function': 'run_etl_hybrid'
            },
            'timestamp': datetime.now().isoformat()
        }), 500

# ==================== AUTHENTIFICATION ====================

def get_youtube_credentials():
    """R√©cup√®re les credentials YouTube OAuth (Brand Account)"""
    try:
        token_json = os.environ.get('YOUTUBE_TOKEN_JSON')
        if not token_json:
            print("‚ö†Ô∏è YOUTUBE_TOKEN_JSON non d√©finie")
            return None
        
        token_data = json.loads(token_json)
        credentials = UserCredentials.from_authorized_user_info(
            token_data,
            scopes=[
                'https://www.googleapis.com/auth/youtube.readonly',
                'https://www.googleapis.com/auth/yt-analytics.readonly'
            ]
        )
        print("‚úÖ Credentials YouTube charg√©s")
        return credentials
        
    except Exception as e:
        print(f"‚ùå Erreur credentials YouTube: {e}")
        return None

def get_sheets_client():
    """R√©cup√®re le client Google Sheets (Service Account)"""
    try:
        print("=== üîç SUPER DEBUG SERVICE ACCOUNT ===")
        
        # 1. V√©rifier la variable d'environnement
        sa_json = os.environ.get('GOOGLE_SA_JSON')
        print(f"üìã Variable exists: {sa_json is not None}")
        
        if not sa_json:
            print("‚ùå GOOGLE_SA_JSON est None ou vide")
            # Lister toutes les variables d'environnement disponibles
            print("üîç Variables disponibles:")
            for key in sorted(os.environ.keys()):
                if 'GOOGLE' in key or 'JSON' in key or 'SA' in key:
                    print(f"   {key}: {len(os.environ[key]) if os.environ[key] else 'VIDE'}")
            return None
        
        # 2. Analyser le contenu
        print(f"üìè Longueur JSON: {len(sa_json)} caract√®res")
        print(f"üî§ Premiers caract√®res: '{sa_json[:50]}'")
        print(f"üî§ Derniers caract√®res: '{sa_json[-50:]}'")
        
        # 3. V√©rifier si c'est du JSON valide
        try:
            sa_data = json.loads(sa_json)
            print("‚úÖ JSON parse r√©ussi")
        except json.JSONDecodeError as je:
            print(f"‚ùå JSON invalide √† position {je.pos}")
            print(f"   Contexte: '{sa_json[max(0, je.pos-20):je.pos+20]}'")
            return None
        
        # 4. Analyser le contenu du JSON
        print(f"üîç Cl√©s JSON: {list(sa_data.keys())}")
        print(f"üîç Type: {sa_data.get('type', 'MANQUANT')}")
        print(f"üîç Project ID: {sa_data.get('project_id', 'MANQUANT')}")
        print(f"üîç Client email: {sa_data.get('client_email', 'MANQUANT')}")
        
        # 5. V√©rifier les champs obligatoires
        required_fields = ['type', 'project_id', 'private_key', 'client_email']
        missing_fields = [field for field in required_fields if field not in sa_data]
        
        if missing_fields:
            print(f"‚ùå Champs manquants: {missing_fields}")
            return None
        
        print("‚úÖ Tous les champs obligatoires pr√©sents")
        
        # 6. Cr√©er les credentials
        print("üîß Cr√©ation des credentials...")
        credentials = ServiceAccountCredentials.from_service_account_info(
            sa_data,
            scopes=[
                'https://www.googleapis.com/auth/spreadsheets',
                'https://www.googleapis.com/auth/drive'
            ]
        )
        print("‚úÖ Credentials cr√©√©s")
        
        # 7. Autoriser gspread
        print("üîß Autorisation gspread...")
        client = gspread.authorize(credentials)
        print("‚úÖ Client gspread autoris√©")
        
        return client
        
    except Exception as e:
        print(f"‚ùå ERREUR INATTENDUE: {type(e).__name__}")
        print(f"   Message: {str(e)}")
        import traceback
        print(f"   Traceback: {traceback.format_exc()}")
        return None

def get_youtube_services(credentials):
    """Initialise les services YouTube SANS CACHE"""
    print("üîß Construction services YouTube...")
    
    # SOLUTION du bug cache multi-utilisateurs
    youtube_service = build(
        'youtube', 'v3',
        credentials=credentials,
        cache_discovery=False  # CRUCIAL !
    )
    
    analytics_service = build(
        'youtubeAnalytics', 'v2',
        credentials=credentials,
        cache_discovery=False  # CRUCIAL !
    )
    
    print("‚úÖ Services YouTube construits (cache d√©sactiv√©)")
    return youtube_service, analytics_service

# ==================== R√âCUP√âRATION DONN√âES ====================

def get_daily_channel_data(analytics_service, start_date, end_date):
    """PHASE 1: R√©cup√®re les donn√©es quotidiennes par cha√Æne"""
    try:
        print(f"üìä Requ√™te Daily Channel Data: {start_date} ‚Üí {end_date}")
        
        response = analytics_service.reports().query(
            ids='channel==MINE',
            startDate=start_date,
            endDate=end_date,
            metrics='views,estimatedMinutesWatched,subscribersGained,subscribersLost,comments,likes,averageViewDuration',
            dimensions='day',
            sort='day'
        ).execute()
        
        rows = response.get('rows', [])
        print(f"‚úÖ Daily Channel Data: {len(rows)} lignes r√©cup√©r√©es")
        
        return rows
        
    except Exception as e:
        print(f"‚ùå Erreur Daily Channel Data: {e}")
        return []

def get_video_performance_data(analytics_service, start_date, end_date):
    """PHASE 2: R√©cup√®re les donn√©es par vid√©o (fen√™tre 7 jours)"""
    try:
        print(f"üìä Requ√™te Video Performance Data: {start_date} ‚Üí {end_date}")
        
        response = analytics_service.reports().query(
            ids='channel==MINE',
            startDate=start_date,
            endDate=end_date,
            metrics='views,estimatedMinutesWatched,likes,dislikes,comments,shares,averageViewDuration',
            dimensions='video',
            maxResults=50
        ).execute()
        
        rows = response.get('rows', [])
        print(f"‚úÖ Video Performance Data: {len(rows)} lignes r√©cup√©r√©es")
        
        return rows
        
    except Exception as e:
        print(f"‚ùå Erreur Video Performance Data: {e}")
        return []

# ==================== SAUVEGARDE ====================

def save_daily_channel_data(sheets_client, daily_rows):
    """Sauvegarde Phase 1 dans Raw_Daily_Data"""
    try:
        print(f"üíæ Sauvegarde Daily Channel Data: {len(daily_rows)} lignes...")
        
        # Ouvrir le spreadsheet
        spreadsheet = sheets_client.open_by_key(SPREADSHEET_ID)
        
        # Utiliser la feuille Raw_Daily_Data existante
        try:
            worksheet = spreadsheet.worksheet('Raw_Daily_Data')
            print("‚úÖ Feuille Raw_Daily_Data trouv√©e")
        except gspread.WorksheetNotFound:
            print("üìã Cr√©ation feuille Raw_Daily_Data...")
            worksheet = spreadsheet.add_worksheet(
                title='Raw_Daily_Data',
                rows=1000,
                cols=8
            )
            # Ajouter les en-t√™tes
            headers = [
                'date', 'total_views', 'total_watch_time', 'subscribers_gained', 
                'subscribers_lost', 'total_comments', 'total_likes', 'avg_view_duration'
            ]
            worksheet.append_row(headers)
            print("‚úÖ Feuille cr√©√©e avec en-t√™tes Daily Channel Data")
        
        # Convertir les donn√©es
        converted_rows = []
        for row in daily_rows:
            converted_row = [
                row[0],  # date
                row[1] if len(row) > 1 else 0,  # total_views
                row[2] if len(row) > 2 else 0,  # total_watch_time
                row[3] if len(row) > 3 else 0,  # subscribers_gained
                row[4] if len(row) > 4 else 0,  # subscribers_lost
                row[5] if len(row) > 5 else 0,  # total_comments
                row[6] if len(row) > 6 else 0,  # total_likes
                row[7] if len(row) > 7 else 0   # avg_view_duration
            ]
            converted_rows.append(converted_row)
        
        # Ajouter les donn√©es
        if converted_rows:
            worksheet.append_rows(converted_rows)
            print(f"‚úÖ {len(converted_rows)} lignes ajout√©es √† Raw_Daily_Data")
        
        return True
        
    except Exception as e:
        print(f"‚ùå Erreur sauvegarde Daily Channel Data: {e}")
        return False

def save_video_performance_data(sheets_client, video_rows):
    """Sauvegarde Phase 2 dans Video_Performance_Data"""
    try:
        print(f"üíæ Sauvegarde Video Performance Data: {len(video_rows)} lignes...")
        
        # Ouvrir le spreadsheet
        spreadsheet = sheets_client.open_by_key(SPREADSHEET_ID)
        
        # V√©rifier/cr√©er la feuille Video_Performance_Data
        try:
            worksheet = spreadsheet.worksheet('Video_Performance_Data')
            print("‚úÖ Feuille Video_Performance_Data trouv√©e")
        except gspread.WorksheetNotFound:
            print("üìã Cr√©ation feuille Video_Performance_Data...")
            worksheet = spreadsheet.add_worksheet(
                title='Video_Performance_Data',
                rows=1000,
                cols=9
            )
            # Ajouter les en-t√™tes
            headers = [
                'video_id', 'views_7d', 'watch_time_7d', 'likes_7d', 'dislikes_7d',
                'comments_7d', 'shares_7d', 'avg_view_duration', 'extraction_date'
            ]
            worksheet.append_row(headers)
            print("‚úÖ Feuille cr√©√©e avec en-t√™tes Video Performance Data")
        
        # Convertir les donn√©es avec date d'extraction
        extraction_date = datetime.now().strftime('%Y-%m-%d')
        converted_rows = []
        for row in video_rows:
            converted_row = [
                row[0],  # video_id
                row[1] if len(row) > 1 else 0,  # views_7d
                row[2] if len(row) > 2 else 0,  # watch_time_7d
                row[3] if len(row) > 3 else 0,  # likes_7d
                row[4] if len(row) > 4 else 0,  # dislikes_7d
                row[5] if len(row) > 5 else 0,  # comments_7d
                row[6] if len(row) > 6 else 0,  # shares_7d
                row[7] if len(row) > 7 else 0,  # avg_view_duration
                extraction_date  # extraction_date
            ]
            converted_rows.append(converted_row)
        
        # Ajouter les donn√©es
        if converted_rows:
            worksheet.append_rows(converted_rows)
            print(f"‚úÖ {len(converted_rows)} lignes ajout√©es √† Video_Performance_Data")
        
        return True
        
    except Exception as e:
        print(f"‚ùå Erreur sauvegarde Video Performance Data: {e}")
        return False

if __name__ == '__main__':
    port = int(os.environ.get('PORT', 8080))
    print("=" * 60)
    print("üöÄ YOUTUBE ETL SERVICE - HYBRIDE PHASE 1 + 2 V5.0")
    print("=" * 60)
    print(f"üåê Port: {port}")
    print(f"üì∫ Channel: {CHANNEL_ID}")
    print(f"üìä Spreadsheet: {SPREADSHEET_ID}")
    print(f"üîê Auth YouTube: OAuth User Token")
    print(f"üîê Auth Sheets: Service Account")
    print("=" * 60)
    print("üìã Endpoints:")
    print("   GET  /           - Accueil")
    print("   GET  /test       - Test basique")
    print("   GET  /test-youtube - Test YouTube seul")
    print("   GET  /test-sheets  - Test Sheets seul")
    print("   GET  /etl        - ETL Hybride Phase 1 + 2")
    print("=" * 60)
    
    app.run(host='0.0.0.0', port=port, debug=True)
